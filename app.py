import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans
import warnings

warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lisis de Rendimiento AcadÃ©mico - IST Azuay",
    page_icon="ðŸ“š",
    layout="wide"
)

# CSS personalizado
st.markdown("""
    <style>
    .main-header {
        text-align: center;
        color: #1f77b4;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

# TÃ­tulo
st.markdown('<div class="main-header">ðŸ“š Sistema de AnÃ¡lisis de Rendimiento AcadÃ©mico</div>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: #666;">Instituto Superior TecnolÃ³gico del Azuay</p>', unsafe_allow_html=True)

# NavegaciÃ³n
st.sidebar.title("ðŸ” NavegaciÃ³n")
page = st.sidebar.radio(
    "Selecciona una secciÃ³n:",
    ["ðŸ  Inicio", "ðŸ“Š ExploraciÃ³n de Datos", "ðŸŽ¯ Modelo Supervisado", "ðŸ” Modelo No Supervisado", "ðŸ“ˆ ComparaciÃ³n"]
)

# ============================================================
# FUNCIONES DE CARGA Y PREPARACIÃ“N
# ============================================================

@st.cache_data
def load_data():
    """Cargar el dataset."""
    df = pd.read_csv("academic_performance_master.csv")
    # Crear variable objetivo: 1=APROBADO, 0=REPROBADO
    df['Aprobado'] = (df['Estado_Asignatura'] == 'APROBADO').astype(int)
    return df

@st.cache_data
def prepare_supervised_data(df):
    """Preparar datos para modelo supervisado."""
    # Seleccionar solo columnas relevantes
    features = ['Asistencia', 'Num_matricula']
    df_clean = df[features + ['Aprobado']].dropna()
    
    X = df_clean[features]
    y = df_clean['Aprobado']
    
    return X, y, features

@st.cache_data
def prepare_clustering_data(df):
    """Preparar datos para clustering."""
    df_cluster = df[['Asistencia', 'Nota_final']].dropna()
    return df_cluster

# Cargar datos
df = load_data()

# ============================================================
# PÃGINA: INICIO
# ============================================================

if page == "ðŸ  Inicio":
    st.header("Bienvenido al Sistema de AnÃ¡lisis AcadÃ©mico")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ðŸ“Š Total de Registros", f"{len(df):,}")
    
    with col2:
        tasa_aprobacion = (df['Aprobado'].sum() / len(df)) * 100
        st.metric("âœ… Tasa de AprobaciÃ³n", f"{tasa_aprobacion:.1f}%")
    
    with col3:
        st.metric("ðŸŽ“ Carreras", df['Carrera'].nunique())
    
    st.markdown("---")
    
    st.subheader("ðŸ“‹ Objetivo del Proyecto")
    st.write("""
    Este sistema implementa **dos modelos de Machine Learning** para analizar el rendimiento acadÃ©mico:
    
    1. **Modelo Supervisado (ClasificaciÃ³n)**: Predice si un estudiante aprobarÃ¡ o reprobarÃ¡
    2. **Modelo No Supervisado (Clustering)**: Agrupa estudiantes con patrones similares
    
    **Dataset**: `academic_performance_master.csv`  
    **Registros**: {:,} estudiantes  
    **Variables clave**: Asistencia, Nota Final, Carrera, Periodo
    """.format(len(df)))
    
    st.markdown("---")
    
    st.subheader("ðŸŽ¯ Â¿CÃ³mo usar esta aplicaciÃ³n?")
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **ðŸ“Š ExploraciÃ³n de Datos**
        - Visualiza distribuciones
        - Identifica patrones
        - EstadÃ­sticas descriptivas
        """)
        
        st.success("""
        **ðŸŽ¯ Modelo Supervisado**
        - RegresiÃ³n LogÃ­stica
        - PredicciÃ³n de aprobaciÃ³n
        - Matriz de confusiÃ³n
        """)
    
    with col2:
        st.warning("""
        **ðŸ” Modelo No Supervisado**
        - K-Means Clustering
        - AgrupaciÃ³n de estudiantes
        - Perfiles acadÃ©micos
        """)
        
        st.error("""
        **ðŸ“ˆ ComparaciÃ³n**
        - AnÃ¡lisis de ambos modelos
        - Conclusiones
        - Recomendaciones
        """)

# ============================================================
# PÃGINA: EXPLORACIÃ“N DE DATOS
# ============================================================

elif page == "ðŸ“Š ExploraciÃ³n de Datos":
    st.header("ðŸ“Š ExploraciÃ³n de Datos")
    
    tab1, tab2, tab3 = st.tabs(["Vista General", "Distribuciones", "Correlaciones"])
    
    with tab1:
        st.subheader("Vista Previa del Dataset")
        st.dataframe(df.head(10), use_container_width=True)
        
        st.subheader("InformaciÃ³n del Dataset")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Dimensiones:**")
            st.write(f"- Filas: {len(df):,}")
            st.write(f"- Columnas: {len(df.columns)}")
            st.write(f"- Valores nulos: {df.isnull().sum().sum()}")
        
        with col2:
            st.write("**Tipos de Datos:**")
            st.dataframe(df.dtypes.reset_index().rename(columns={0: 'Tipo', 'index': 'Columna'}))
        
        st.subheader("EstadÃ­sticas Descriptivas")
        st.dataframe(df.describe(), use_container_width=True)
    
    with tab2:
        st.subheader("DistribuciÃ³n de Variables Clave")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # DistribuciÃ³n de Nota Final
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(df['Nota_final'].dropna(), bins=20, color='skyblue', edgecolor='black')
            ax.axvline(7, color='red', linestyle='--', linewidth=2, label='Nota MÃ­nima (7.0)')
            ax.set_title('DistribuciÃ³n de Nota Final', fontsize=14, fontweight='bold')
            ax.set_xlabel('Nota Final')
            ax.set_ylabel('Frecuencia')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
            
            # MÃ©tricas de Nota Final
            st.metric("Media", f"{df['Nota_final'].mean():.2f}")
            st.metric("DesviaciÃ³n EstÃ¡ndar", f"{df['Nota_final'].std():.2f}")
        
        with col2:
            # DistribuciÃ³n de Asistencia
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(df['Asistencia'].dropna(), bins=20, color='lightgreen', edgecolor='black')
            ax.set_title('DistribuciÃ³n de Asistencia', fontsize=14, fontweight='bold')
            ax.set_xlabel('Asistencia (%)')
            ax.set_ylabel('Frecuencia')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
            
            # MÃ©tricas de Asistencia
            st.metric("Media", f"{df['Asistencia'].mean():.1f}%")
            st.metric("DesviaciÃ³n EstÃ¡ndar", f"{df['Asistencia'].std():.1f}%")
        
        # DistribuciÃ³n Aprobados/Reprobados
        st.subheader("DistribuciÃ³n de Aprobados vs Reprobados")
        fig, ax = plt.subplots(figsize=(10, 5))
        counts = df['Aprobado'].value_counts()
        colors = ['salmon', 'lightblue']
        ax.bar(['Reprobados', 'Aprobados'], counts.values, color=colors, edgecolor='black', width=0.6)
        ax.set_ylabel('Cantidad de Estudiantes')
        ax.set_title('DistribuciÃ³n de Estudiantes Aprobados/Reprobados', fontsize=14, fontweight='bold')
        for i, v in enumerate(counts.values):
            ax.text(i, v + 100, str(v), ha='center', fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')
        st.pyplot(fig)
        plt.close()
    
    with tab3:
        st.subheader("RelaciÃ³n entre Variables")
        
        # Scatter plot: Asistencia vs Nota Final
        fig, ax = plt.subplots(figsize=(10, 6))
        sample = df.sample(n=min(3000, len(df)), random_state=42)
        scatter = ax.scatter(sample['Asistencia'], sample['Nota_final'], 
                           c=sample['Aprobado'], cmap='RdYlGn', 
                           alpha=0.5, edgecolors='black', s=30)
        ax.set_xlabel('Asistencia (%)', fontsize=12)
        ax.set_ylabel('Nota Final', fontsize=12)
        ax.set_title('Asistencia vs Nota Final (Muestra)', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='Aprobado (1=SÃ­, 0=No)')
        st.pyplot(fig)
        plt.close()
        
        # CorrelaciÃ³n
        corr = df[['Asistencia', 'Nota_final', 'Aprobado']].corr()
        st.subheader("Matriz de CorrelaciÃ³n")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(corr, annot=True, fmt='.3f', cmap='coolwarm', 
                   center=0, square=True, linewidths=1, ax=ax)
        ax.set_title('CorrelaciÃ³n entre Variables', fontsize=14, fontweight='bold')
        st.pyplot(fig)
        plt.close()

# ============================================================
# PÃGINA: MODELO SUPERVISADO
# ============================================================

elif page == "ðŸŽ¯ Modelo Supervisado":
    st.header("ðŸŽ¯ Modelo Supervisado - ClasificaciÃ³n")
    st.markdown("**PredicciÃ³n de AprobaciÃ³n usando RegresiÃ³n LogÃ­stica**")
    
    # Preparar datos
    X, y, features = prepare_supervised_data(df)
    
    st.sidebar.subheader("âš™ï¸ ConfiguraciÃ³n del Modelo")
    test_size = st.sidebar.slider("TamaÃ±o del conjunto de prueba", 0.1, 0.5, 0.3, 0.05)
    random_state = st.sidebar.number_input("Semilla aleatoria", 1, 100, 42)
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # Escalar datos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Mostrar informaciÃ³n de los datos
    st.subheader("ðŸ“Š InformaciÃ³n del Dataset")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total de datos", len(X))
    col2.metric("Entrenamiento", len(X_train))
    col3.metric("Prueba", len(X_test))
    col4.metric("Features", len(features))
    
    st.write(f"**Features seleccionados:** {', '.join(features)}")
    
    # Entrenar modelo
    if st.button("ðŸš€ Entrenar Modelo de RegresiÃ³n LogÃ­stica", type="primary", use_container_width=True):
        with st.spinner("Entrenando modelo..."):
            # Entrenar
            model = LogisticRegression(random_state=random_state, max_iter=1000)
            model.fit(X_train_scaled, y_train)
            
            # Predicciones
            y_pred_train = model.predict(X_train_scaled)
            y_pred_test = model.predict(X_test_scaled)
            
            # MÃ©tricas
            train_accuracy = accuracy_score(y_train, y_pred_train)
            test_accuracy = accuracy_score(y_test, y_pred_test)
            
            st.success("âœ… Modelo entrenado exitosamente!")
            
            # Mostrar resultados
            st.subheader("ðŸ“ˆ Resultados del Modelo")
            
            col1, col2, col3 = st.columns(3)
            col1.metric("ðŸŽ¯ Accuracy (Entrenamiento)", f"{train_accuracy:.2%}")
            col2.metric("ðŸŽ¯ Accuracy (Prueba)", f"{test_accuracy:.2%}")
            col3.metric("ðŸ“Š Diferencia", f"{abs(train_accuracy - test_accuracy):.2%}")
            
            # Matriz de ConfusiÃ³n
            st.subheader("ðŸ”² Matriz de ConfusiÃ³n")
            cm = confusion_matrix(y_test, y_pred_test)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=['Reprobado', 'Aprobado'],
                       yticklabels=['Reprobado', 'Aprobado'],
                       cbar_kws={'label': 'Cantidad'},
                       linewidths=2, linecolor='black', ax=ax)
            ax.set_ylabel('Valor Real', fontsize=12, fontweight='bold')
            ax.set_xlabel('PredicciÃ³n', fontsize=12, fontweight='bold')
            ax.set_title('Matriz de ConfusiÃ³n - Modelo Supervisado', fontsize=14, fontweight='bold')
            st.pyplot(fig)
            plt.close()
            
            # InterpretaciÃ³n de la matriz
            tn, fp, fn, tp = cm.ravel()
            st.write(f"""
            **InterpretaciÃ³n de la Matriz de ConfusiÃ³n:**
            - âœ… **Verdaderos Negativos (TN)**: {tn} - Correctamente predijo reprobados
            - âŒ **Falsos Positivos (FP)**: {fp} - Predijo aprobado pero era reprobado
            - âŒ **Falsos Negativos (FN)**: {fn} - Predijo reprobado pero era aprobado
            - âœ… **Verdaderos Positivos (TP)**: {tp} - Correctamente predijo aprobados
            """)
            
            # Reporte de ClasificaciÃ³n
            st.subheader("ðŸ“‹ Reporte de ClasificaciÃ³n Detallado")
            report = classification_report(y_test, y_pred_test, 
                                          target_names=['Reprobado', 'Aprobado'],
                                          output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df.style.format("{:.4f}"), use_container_width=True)
            
            # Importancia de features
            if hasattr(model, 'coef_'):
                st.subheader("ðŸ“Š Importancia de Variables")
                
                feature_importance = pd.DataFrame({
                    'Feature': features,
                    'Coeficiente': model.coef_[0],
                    'Importancia': np.abs(model.coef_[0])
                }).sort_values('Importancia', ascending=False)
                
                fig, ax = plt.subplots(figsize=(10, 5))
                colors = ['green' if x > 0 else 'red' for x in feature_importance['Coeficiente']]
                ax.barh(feature_importance['Feature'], feature_importance['Importancia'], 
                       color=colors, edgecolor='black')
                ax.set_xlabel('Importancia Absoluta', fontsize=12)
                ax.set_title('Importancia de Variables en la PredicciÃ³n', fontsize=14, fontweight='bold')
                ax.grid(True, alpha=0.3, axis='x')
                st.pyplot(fig)
                plt.close()
                
                st.dataframe(feature_importance, use_container_width=True, hide_index=True)
            
            # InterpretaciÃ³n final
            st.markdown("---")
            st.subheader("ðŸ’¡ InterpretaciÃ³n de Resultados")
            
            if test_accuracy >= 0.85:
                st.success(f"""
                âœ… **Excelente rendimiento del modelo ({test_accuracy:.2%})**
                - El modelo es muy confiable para predecir aprobaciÃ³n/reprobaciÃ³n
                - Alta precisiÃ³n en ambas clases
                """)
            elif test_accuracy >= 0.75:
                st.info(f"""
                ðŸ‘ **Buen rendimiento del modelo ({test_accuracy:.2%})**
                - El modelo es Ãºtil para predicciones
                - Se puede mejorar con mÃ¡s features
                """)
            else:
                st.warning(f"""
                âš ï¸ **Rendimiento moderado del modelo ({test_accuracy:.2%})**
                - Considerar agregar mÃ¡s variables predictoras
                - Evaluar otros algoritmos
                """)
            
            st.write("""
            **Conclusiones del Modelo Supervisado:**
            - Tipo: **Aprendizaje Supervisado (ClasificaciÃ³n)**
            - Algoritmo: **RegresiÃ³n LogÃ­stica**
            - Objetivo: Predecir si un estudiante aprobarÃ¡ o reprobarÃ¡
            - Variables mÃ¡s influyentes: {}
            """.format(', '.join(feature_importance.head(2)['Feature'].tolist())))

# ============================================================
# PÃGINA: MODELO NO SUPERVISADO
# ============================================================

elif page == "ðŸ” Modelo No Supervisado":
    st.header("ðŸ” Modelo No Supervisado - Clustering")
    st.markdown("**AgrupaciÃ³n de estudiantes usando K-Means**")
    
    # Preparar datos
    df_cluster = prepare_clustering_data(df)
    
    st.sidebar.subheader("âš™ï¸ ConfiguraciÃ³n de K-Means")
    n_clusters = st.sidebar.slider("NÃºmero de clusters (k)", 2, 5, 3)
    random_state = st.sidebar.number_input("Semilla aleatoria", 1, 100, 42)
    
    st.subheader("ðŸ“Š InformaciÃ³n del Dataset para Clustering")
    col1, col2 = st.columns(2)
    col1.metric("Registros vÃ¡lidos", len(df_cluster))
    col2.metric("Features", "Asistencia, Nota_final")
    
    # Mostrar muestra de datos
    st.write("**Muestra de datos para clustering:**")
    st.dataframe(df_cluster.head(10), use_container_width=True)
    
    if st.button("ðŸ” Aplicar K-Means Clustering", type="primary", use_container_width=True):
        with st.spinner("Aplicando clustering..."):
            # Escalar datos
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df_cluster)
            
            # Aplicar K-Means
            kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)
            clusters = kmeans.fit_predict(X_scaled)
            
            # Agregar clusters al dataframe
            df_cluster['Cluster'] = clusters
            
            st.success(f"âœ… Clustering completado con {n_clusters} grupos!")
            
            # VisualizaciÃ³n principal
            st.subheader("ðŸ“Š VisualizaciÃ³n de Clusters")
            
            fig, ax = plt.subplots(figsize=(12, 8))
            
            # Graficar cada cluster con diferente color
            colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))
            for i in range(n_clusters):
                cluster_data = df_cluster[df_cluster['Cluster'] == i]
                ax.scatter(cluster_data['Asistencia'], cluster_data['Nota_final'],
                          c=[colors[i]], label=f'Cluster {i}', 
                          alpha=0.6, s=100, edgecolors='black', linewidth=0.5)
            
            # Graficar centroides
            centroids = scaler.inverse_transform(kmeans.cluster_centers_)
            ax.scatter(centroids[:, 0], centroids[:, 1],
                      c='red', s=500, alpha=0.9, marker='X',
                      edgecolors='black', linewidths=3, label='Centroides')
            
            ax.set_xlabel('Asistencia (%)', fontsize=14, fontweight='bold')
            ax.set_ylabel('Nota Final', fontsize=14, fontweight='bold')
            ax.set_title(f'K-Means Clustering (k={n_clusters})', fontsize=16, fontweight='bold')
            ax.legend(fontsize=12, loc='best')
            ax.grid(True, alpha=0.3)
            
            st.pyplot(fig)
            plt.close()
            
            # EstadÃ­sticas por cluster
            st.subheader("ðŸ“Š EstadÃ­sticas por Cluster")
            
            cluster_stats = df_cluster.groupby('Cluster').agg({
                'Asistencia': ['mean', 'std', 'min', 'max', 'count'],
                'Nota_final': ['mean', 'std', 'min', 'max']
            }).round(2)
            
            cluster_stats.columns = ['_'.join(col).strip() for col in cluster_stats.columns.values]
            cluster_stats = cluster_stats.reset_index()
            
            st.dataframe(cluster_stats, use_container_width=True)
            
            # DistribuciÃ³n de clusters
            st.subheader("ðŸ“ˆ DistribuciÃ³n de Estudiantes por Cluster")
            
            fig, ax = plt.subplots(figsize=(10, 5))
            cluster_counts = df_cluster['Cluster'].value_counts().sort_index()
            bars = ax.bar(cluster_counts.index, cluster_counts.values, 
                         color=colors[:n_clusters], edgecolor='black', width=0.6)
            
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(height)}\n({height/len(df_cluster)*100:.1f}%)',
                       ha='center', va='bottom', fontweight='bold')
            
            ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')
            ax.set_ylabel('Cantidad de Estudiantes', fontsize=12, fontweight='bold')
            ax.set_title('DistribuciÃ³n de Estudiantes por Cluster', fontsize=14, fontweight='bold')
            ax.grid(True, alpha=0.3, axis='y')
            st.pyplot(fig)
            plt.close()
            
            # InterpretaciÃ³n de clusters
            st.markdown("---")
            st.subheader("ðŸ’¡ InterpretaciÃ³n de Clusters")
            
            for i in range(n_clusters):
                cluster_data = df_cluster[df_cluster['Cluster'] == i]
                avg_asistencia = cluster_data['Asistencia'].mean()
                avg_nota = cluster_data['Nota_final'].mean()
                count = len(cluster_data)
                
                # Determinar perfil
                if avg_nota >= 8 and avg_asistencia >= 85:
                    perfil = "ðŸŒŸ **Estudiantes Exitosos**"
                    descripcion = "Alta asistencia y excelentes notas. Son estudiantes modelo."
                    color = "success"
                elif avg_nota < 7 and avg_asistencia < 70:
                    perfil = "âš ï¸ **Estudiantes en Riesgo**"
                    descripcion = "Baja asistencia y notas bajas. **Requieren intervenciÃ³n urgente.**"
                    color = "error"
                elif avg_asistencia >= 80 and avg_nota < 7.5:
                    perfil = "ðŸ¤” **Necesitan Apoyo AcadÃ©mico**"
                    descripcion = "Buena asistencia pero dificultades acadÃ©micas. Necesitan tutorÃ­as."
                    color = "warning"
                else:
                    perfil = "ðŸ“ˆ **Rendimiento Medio**"
                    descripcion = "Rendimiento aceptable con margen de mejora."
                    color = "info"
                
                # Mostrar anÃ¡lisis del cluster
                with st.expander(f"**Cluster {i}** - {count} estudiantes ({count/len(df_cluster)*100:.1f}%)"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("ðŸ‘¥ Cantidad", count)
                        st.metric("ðŸ“Š Asistencia Promedio", f"{avg_asistencia:.1f}%")
                        st.metric("ðŸ“ Nota Promedio", f"{avg_nota:.2f}")
                    
                    with col2:
                        if color == "success":
                            st.success(f"""
                            {perfil}
                            
                            {descripcion}
                            
                            **CaracterÃ­sticas:**
                            - Asistencia: {avg_asistencia:.1f}%
                            - Nota: {avg_nota:.2f}
                            """)
                        elif color == "error":
                            st.error(f"""
                            {perfil}
                            
                            {descripcion}
                            
                            **CaracterÃ­sticas:**
                            - Asistencia: {avg_asistencia:.1f}%
                            - Nota: {avg_nota:.2f}
                            """)
                        elif color == "warning":
                            st.warning(f"""
                            {perfil}
                            
                            {descripcion}
                            
                            **CaracterÃ­sticas:**
                            - Asistencia: {avg_asistencia:.1f}%
                            - Nota: {avg_nota:.2f}
                            """)
                        else:
                            st.info(f"""
                            {perfil}
                            
                            {descripcion}
                            
                            **CaracterÃ­sticas:**
                            - Asistencia: {avg_asistencia:.1f}%
                            - Nota: {avg_nota:.2f}
                            """)
            
            # Conclusiones
            st.markdown("---")
            st.subheader("ðŸ“ Conclusiones del Clustering")
            st.write("""
            **Tipo de Modelo:** Aprendizaje No Supervisado (Clustering)
            
            **Algoritmo:** K-Means
            
            **Objetivo:** Agrupar estudiantes con patrones similares de rendimiento
            
            **Hallazgos clave:**
            - Se identificaron {} grupos distintos de estudiantes
            - Los clusters revelan patrones claros de rendimiento acadÃ©mico
            - La asistencia es un factor diferenciador importante entre grupos
            - Permite personalizar estrategias de apoyo por perfil de estudiante
            """.format(n_clusters))
